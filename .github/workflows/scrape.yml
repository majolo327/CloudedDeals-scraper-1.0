name: Daily Scrape

on:
  schedule:
    # 8:45 AM EST = 13:45 UTC
    - cron: "45 13 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # =========================================================================
      # SUPABASE MIGRATIONS
      # =========================================================================
      # Runs all pending SQL migrations from clouded-deals/supabase/migrations/
      # Requires SUPABASE_DB_URL secret in format:
      #   postgresql://postgres:[password]@db.[project-ref].supabase.co:5432/postgres
      #
      # To get your DB URL:
      # 1. Go to Supabase Dashboard > Project Settings > Database
      # 2. Copy the "Connection string" (URI format)
      # 3. Add as repository secret named SUPABASE_DB_URL
      # =========================================================================
      - name: Run Supabase migrations
        if: ${{ secrets.SUPABASE_DB_URL != '' }}
        env:
          SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: |
          # Install PostgreSQL client
          sudo apt-get update && sudo apt-get install -y postgresql-client

          # Run each migration file in order
          MIGRATIONS_DIR="clouded-deals/supabase/migrations"

          if [ -d "$MIGRATIONS_DIR" ]; then
            echo "üì¶ Found migrations directory"

            # Get list of migration files sorted by name
            MIGRATION_FILES=$(find "$MIGRATIONS_DIR" -name "*.sql" -type f | sort)

            if [ -z "$MIGRATION_FILES" ]; then
              echo "‚ÑπÔ∏è  No migration files found, skipping"
            else
              echo "üîÑ Running migrations..."

              for file in $MIGRATION_FILES; do
                echo "  ‚Üí Running: $(basename $file)"
                # Run migration, continue on error (idempotent migrations)
                psql "$SUPABASE_DB_URL" -f "$file" 2>&1 || echo "    ‚ö†Ô∏è  Migration may have already been applied"
              done

              echo "‚úÖ Migrations complete"
            fi
          else
            echo "‚ÑπÔ∏è  No migrations directory found at $MIGRATIONS_DIR"
          fi

      - name: Skip migrations (no DB URL configured)
        if: ${{ secrets.SUPABASE_DB_URL == '' }}
        run: |
          echo "‚ö†Ô∏è  SUPABASE_DB_URL secret not configured, skipping migrations"
          echo "   To enable automatic migrations, add SUPABASE_DB_URL secret"
          echo "   See workflow comments for setup instructions"

      - name: Install Python dependencies
        working-directory: clouded-deals/scraper
        run: pip install -r requirements.txt

      - name: Install Playwright system dependencies
        run: playwright install-deps

      - name: Install Playwright Chromium
        run: playwright install chromium

      - name: Run scraper
        working-directory: clouded-deals/scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python main.py
