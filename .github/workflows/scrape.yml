name: Daily Scraper

# Dynamic run name — each scheduled region is identifiable at a glance in the
# Actions UI (e.g. "Scrape — nevada", "Scrape — michigan (2/4)").
run-name: >-
  Scrape — ${{
    github.event_name == 'workflow_dispatch'
      && format('{0}{1}', github.event.inputs.region || 'all',
           github.event.inputs.dry_run == 'true' && ' (dry-run)' || '')
    || contains(github.event.schedule || '', '0 13') && 'new-york (1/2)'
    || contains(github.event.schedule || '', '2 13') && 'new-york (2/2)'
    || contains(github.event.schedule || '', '0 14') && 'new-jersey (1/4)'
    || contains(github.event.schedule || '', '2 14') && 'new-jersey (2/4)'
    || contains(github.event.schedule || '', '4 14') && 'new-jersey (3/4)'
    || contains(github.event.schedule || '', '6 14') && 'new-jersey (4/4)'
    || contains(github.event.schedule || '', '0 15') && 'ohio (1/4)'
    || contains(github.event.schedule || '', '2 15') && 'ohio (2/4)'
    || contains(github.event.schedule || '', '4 15') && 'ohio (3/4)'
    || contains(github.event.schedule || '', '6 15') && 'ohio (4/4)'
    || contains(github.event.schedule || '', '0 16') && 'southern-nv'
    || contains(github.event.schedule || '', '2 16') && 'northern-nv'
    || contains(github.event.schedule || '', '0 17') && 'michigan (1/6)'
    || contains(github.event.schedule || '', '2 17') && 'michigan (2/6)'
    || contains(github.event.schedule || '', '4 17') && 'michigan (3/6)'
    || contains(github.event.schedule || '', '6 17') && 'michigan (4/6)'
    || contains(github.event.schedule || '', '8 17') && 'michigan (5/6)'
    || contains(github.event.schedule || '', '10 17') && 'michigan (6/6)'
    || contains(github.event.schedule || '', '0 18') && 'illinois (1/3)'
    || contains(github.event.schedule || '', '2 18') && 'illinois (2/3)'
    || contains(github.event.schedule || '', '4 18') && 'illinois (3/3)'
    || contains(github.event.schedule || '', '0 19') && 'arizona (1/2)'
    || contains(github.event.schedule || '', '2 19') && 'arizona (2/2)'
    || contains(github.event.schedule || '', '0 20') && 'colorado (1/3)'
    || contains(github.event.schedule || '', '2 20') && 'colorado (2/3)'
    || contains(github.event.schedule || '', '4 20') && 'colorado (3/3)'
    || contains(github.event.schedule || '', '0 21') && 'missouri (1/4)'
    || contains(github.event.schedule || '', '2 21') && 'missouri (2/4)'
    || contains(github.event.schedule || '', '4 21') && 'missouri (3/4)'
    || contains(github.event.schedule || '', '6 21') && 'missouri (4/4)'
    || contains(github.event.schedule || '', '0 22') && 'pennsylvania'
    || contains(github.event.schedule || '', '0 23') && 'massachusetts (1/2)'
    || contains(github.event.schedule || '', '2 23') && 'massachusetts (2/2)'
    || 'scheduled'
  }}

on:
  schedule:
    # 33 cron jobs across 12 regions, each state in its own hour slot.
    # States with 60+ sites are sharded into parallel jobs of ~60 sites
    # each via round-robin in main.py.  Spread 8 AM–6 PM local so GHA
    # runners aren't competing.  NV is the production anchor at 8 AM PDT.
    # PA & MA run late afternoon so store menus are fully updated.
    # GHA crons run 5-30 min late — account for that.
    #
    # DST-ADJUSTED (Mar 8 2026): All times shifted -1hr UTC to preserve
    # local times after spring-forward.  Arizona stays unchanged (no DST).
    #
    # ── 8:00 AM EDT — New York ───────────────────────────────────
    - cron: "0 12 * * *"    # new-york-1         — 8:00 AM EDT  (shard 1/2, ~37 sites)
    - cron: "2 12 * * *"    # new-york-2         — 8:02 AM EDT  (shard 2/2, ~37 sites)
    #
    # ── 9:00 AM EDT — New Jersey ─────────────────────────────────
    - cron: "0 13 * * *"    # new-jersey-1       — 9:00 AM EDT  (shard 1/4, ~58 sites)
    - cron: "2 13 * * *"    # new-jersey-2       — 9:02 AM EDT  (shard 2/4, ~58 sites)
    - cron: "4 13 * * *"    # new-jersey-3       — 9:04 AM EDT  (shard 3/4, ~58 sites)
    - cron: "6 13 * * *"    # new-jersey-4       — 9:06 AM EDT  (shard 4/4, ~58 sites)
    #
    # ── 10:00 AM EDT — Ohio ──────────────────────────────────────
    - cron: "0 14 * * *"    # ohio-1             — 10:00 AM EDT (shard 1/4, ~62 sites)
    - cron: "2 14 * * *"    # ohio-2             — 10:02 AM EDT (shard 2/4, ~62 sites)
    - cron: "4 14 * * *"    # ohio-3             — 10:04 AM EDT (shard 3/4, ~62 sites)
    - cron: "6 14 * * *"    # ohio-4             — 10:06 AM EDT (shard 4/4, ~62 sites)
    #
    # ── 8:00 AM PDT — Nevada ★ production anchor ────────────────
    - cron: "0 15 * * *"    # southern-nv        — 8:00 AM PDT  (53 sites) ★
    - cron: "2 15 * * *"    # northern-nv        — 8:02 AM PDT  (~40 sites)
    #
    # ── 12:00 PM EDT — Michigan ──────────────────────────────────
    - cron: "0 16 * * *"    # michigan-1         — 12:00 PM EDT (shard 1/6, ~75 sites)
    - cron: "2 16 * * *"    # michigan-2         — 12:02 PM EDT (shard 2/6, ~75 sites)
    - cron: "4 16 * * *"    # michigan-3         — 12:04 PM EDT (shard 3/6, ~75 sites)
    - cron: "6 16 * * *"    # michigan-4         — 12:06 PM EDT (shard 4/6, ~74 sites)
    - cron: "8 16 * * *"    # michigan-5         — 12:08 PM EDT (shard 5/6, ~74 sites)
    - cron: "10 16 * * *"   # michigan-6         — 12:10 PM EDT (shard 6/6, ~74 sites)
    #
    # ── 12:00 PM CDT — Illinois ──────────────────────────────────
    - cron: "0 17 * * *"    # illinois-1         — 12:00 PM CDT (shard 1/3, ~55 sites)
    - cron: "2 17 * * *"    # illinois-2         — 12:02 PM CDT (shard 2/3, ~55 sites)
    - cron: "4 17 * * *"    # illinois-3         — 12:04 PM CDT (shard 3/3, ~55 sites)
    #
    # ── 12:00 PM MST — Arizona (NO DST — unchanged) ─────────────
    - cron: "0 19 * * *"    # arizona-1          — 12:00 PM MST (shard 1/2, ~50 sites)
    - cron: "2 19 * * *"    # arizona-2          — 12:02 PM MST (shard 2/2, ~50 sites)
    #
    # ── 1:00 PM MDT — Colorado ───────────────────────────────────
    # Shares UTC 19 with Arizona but uses :04/:06/:08 minute offsets
    # to keep concurrency groups unique.
    - cron: "4 19 * * *"    # colorado-1         — 1:04 PM MDT  (shard 1/3, ~44 sites)
    - cron: "6 19 * * *"    # colorado-2         — 1:06 PM MDT  (shard 2/3, ~44 sites)
    - cron: "8 19 * * *"    # colorado-3         — 1:08 PM MDT  (shard 3/3, ~45 sites)
    #
    # ── 3:00 PM CDT — Missouri ───────────────────────────────────
    - cron: "0 20 * * *"    # missouri-1         — 3:00 PM CDT  (shard 1/4, ~65 sites)
    - cron: "2 20 * * *"    # missouri-2         — 3:02 PM CDT  (shard 2/4, ~65 sites)
    - cron: "4 20 * * *"    # missouri-3         — 3:04 PM CDT  (shard 3/4, ~65 sites)
    - cron: "6 20 * * *"    # missouri-4         — 3:06 PM CDT  (shard 4/4, ~66 sites)
    #
    # ── 5:00 PM EDT — Pennsylvania ───────────────────────────────
    # (late afternoon — stores open & menus updated all day)
    - cron: "0 21 * * *"    # pennsylvania       — 5:00 PM EDT  (~43 sites)
    #
    # ── 6:00 PM EDT — Massachusetts ──────────────────────────────
    # (late afternoon — stores open & menus updated all day)
    - cron: "0 22 * * *"    # massachusetts-1    — 6:00 PM EDT  (shard 1/2, ~56 sites)
    - cron: "2 22 * * *"    # massachusetts-2    — 6:02 PM EDT  (shard 2/2, ~55 sites)
  workflow_dispatch:
    inputs:
      platform_group:
        description: "Platform group to scrape"
        required: false
        type: choice
        options:
          - all
          - stable
          - new
        default: "all"
      region:
        description: "Region/state to scrape (sharded states support -1, -2, etc.)"
        required: false
        type: choice
        options:
          - all
          - southern-nv
          - northern-nv
          - michigan
          - michigan-1
          - michigan-2
          - michigan-3
          - michigan-4
          - michigan-5
          - michigan-6
          - illinois
          - illinois-1
          - illinois-2
          - illinois-3
          - arizona
          - arizona-1
          - arizona-2
          - colorado
          - colorado-1
          - colorado-2
          - colorado-3
          - missouri
          - missouri-1
          - missouri-2
          - missouri-3
          - missouri-4
          - new-jersey
          - new-jersey-1
          - new-jersey-2
          - new-jersey-3
          - new-jersey-4
          - massachusetts
          - massachusetts-1
          - massachusetts-2
          - ohio
          - ohio-1
          - ohio-2
          - ohio-3
          - ohio-4
          - new-york
          - new-york-1
          - new-york-2
          - pennsylvania
        default: "all"
      dry_run:
        description: "Dry run (scrape but don't write to DB)"
        required: false
        type: boolean
        default: false
      limit_dispensaries:
        description: "Test with limited dispensaries (1 per platform)"
        required: false
        type: boolean
        default: false
      single_site:
        description: "Scrape a single site by slug (e.g. td-gibson)"
        required: false
        type: string
        default: ""
      force_run:
        description: "Force run even if this region already scraped today"
        required: false
        type: boolean
        default: true

# Concurrency is scoped per-region so each state runs independently.
# Scheduled runs key off the cron expression; manual runs key off region input.
concurrency:
  group: scraper-${{ github.event.schedule || github.event.inputs.region || 'default' }}
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Determine region
        id: region
        run: |
          # DST-ADJUSTED (Mar 8 2026): cron expressions shifted -1hr UTC.
          # Arizona unchanged (no DST). Colorado uses :04/:06/:08 offsets at
          # UTC 19 to avoid concurrency-group collision with Arizona.
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "value=${{ github.event.inputs.region || 'all' }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 12 * * *" ]; then
            echo "value=new-york-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 12 * * *" ]; then
            echo "value=new-york-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 13 * * *" ]; then
            echo "value=new-jersey-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 13 * * *" ]; then
            echo "value=new-jersey-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 13 * * *" ]; then
            echo "value=new-jersey-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "6 13 * * *" ]; then
            echo "value=new-jersey-4" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 14 * * *" ]; then
            echo "value=ohio-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 14 * * *" ]; then
            echo "value=ohio-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 14 * * *" ]; then
            echo "value=ohio-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "6 14 * * *" ]; then
            echo "value=ohio-4" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 15 * * *" ]; then
            echo "value=southern-nv" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 15 * * *" ]; then
            echo "value=northern-nv" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 16 * * *" ]; then
            echo "value=michigan-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 16 * * *" ]; then
            echo "value=michigan-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 16 * * *" ]; then
            echo "value=michigan-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "6 16 * * *" ]; then
            echo "value=michigan-4" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "8 16 * * *" ]; then
            echo "value=michigan-5" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "10 16 * * *" ]; then
            echo "value=michigan-6" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 17 * * *" ]; then
            echo "value=illinois-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 17 * * *" ]; then
            echo "value=illinois-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 17 * * *" ]; then
            echo "value=illinois-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 19 * * *" ]; then
            echo "value=arizona-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 19 * * *" ]; then
            echo "value=arizona-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 19 * * *" ]; then
            echo "value=colorado-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "6 19 * * *" ]; then
            echo "value=colorado-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "8 19 * * *" ]; then
            echo "value=colorado-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 20 * * *" ]; then
            echo "value=missouri-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 20 * * *" ]; then
            echo "value=missouri-2" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "4 20 * * *" ]; then
            echo "value=missouri-3" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "6 20 * * *" ]; then
            echo "value=missouri-4" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 21 * * *" ]; then
            echo "value=pennsylvania" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "0 22 * * *" ]; then
            echo "value=massachusetts-1" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" = "2 22 * * *" ]; then
            echo "value=massachusetts-2" >> $GITHUB_OUTPUT
          else
            echo "::error::Unknown schedule '${{ github.event.schedule }}' — cannot determine region"
            exit 1
          fi

      - name: Startup jitter
        if: github.event_name == 'schedule'
        run: |
          # Random 0-180s delay so daily crons don't start at the exact
          # same second every day — reduces bot-detection fingerprint.
          JITTER=$((RANDOM % 180))
          echo "Sleeping ${JITTER}s for cron jitter…"
          sleep "$JITTER"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: clouded-deals/scraper/requirements.txt

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('clouded-deals/scraper/requirements.txt') }}

      - name: Install dependencies
        working-directory: clouded-deals/scraper
        run: |
          pip install -r requirements.txt
          playwright install-deps
          playwright install chrome chromium

      - name: Test Supabase connection
        working-directory: clouded-deals/scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python test_connection.py

      - name: "Run scraper [${{ steps.region.outputs.value }}]"
        working-directory: clouded-deals/scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SENTRY_DSN: ${{ secrets.SENTRY_SCRAPER_DSN }}
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
          LIMIT_DISPENSARIES: ${{ github.event.inputs.limit_dispensaries || 'false' }}
          SINGLE_SITE: ${{ github.event.inputs.single_site || '' }}
          # Idempotency check is now region-aware so scheduled runs
          # rely on it to prevent duplicate scrapes.  Manual dispatches
          # default to force_run=true to allow re-running a region.
          FORCE_RUN: ${{ github.event.inputs.force_run || 'false' }}
          PLATFORM_GROUP: ${{ github.event.inputs.platform_group || 'stable' }}
          REGION: ${{ steps.region.outputs.value }}
        run: |
          echo "=== Scraper Configuration ==="
          echo "Region:     $REGION"
          echo "Group:      $PLATFORM_GROUP"
          echo "Dry run:    $DRY_RUN"
          echo "Limited:    $LIMIT_DISPENSARIES"
          echo "Single:     $SINGLE_SITE"
          echo "Force:      $FORCE_RUN"
          echo "============================="

          if [ -n "$SINGLE_SITE" ]; then
            python main.py "$SINGLE_SITE"
          else
            python main.py
          fi

      - name: "Show scrape summary [${{ steps.region.outputs.value }}]"
        if: always()
        working-directory: clouded-deals/scraper
        env:
          REGION: ${{ steps.region.outputs.value }}
        run: |
          if [ -f scrape_summary.txt ]; then
            echo "### Scrape Summary — ${REGION}" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat scrape_summary.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo ""
            echo "=== Scrape Summary — ${REGION} ==="
            cat scrape_summary.txt
          else
            echo "No scrape_summary.txt found (scraper may have crashed before report)"
          fi

      - name: Upload debug screenshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots-${{ steps.region.outputs.value }}-${{ github.run_id }}
          path: |
            clouded-deals/scraper/debug_screenshots/
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload scrape summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-summary-${{ steps.region.outputs.value }}-${{ github.run_id }}
          path: |
            clouded-deals/scraper/scrape_summary.txt
          retention-days: 30
          if-no-files-found: ignore

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-${{ steps.region.outputs.value }}-${{ github.run_id }}
          path: |
            clouded-deals/scraper/*.log
          retention-days: 7
